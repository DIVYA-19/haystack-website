{"componentChunkName":"component---src-templates-doc-template-js","path":"/haystack-io/en/docs/termsmd","result":{"data":{"markdownRemark":{"frontmatter":{"id":"termsmd","title":"Glossary"}},"allFile":{"edges":[{"node":{"relativeDirectory":"layout","childLayoutJson":{"layout":{"header":{"quick":"Quick Start","benchmarks":"Benchmarks","why":"Why Haystack","gui":"Admin","tutorials":"Tutorials","solution":"Scenarios","about":"About Haystack","doc":"Docs","blog":"Blog","try":"Try","loading":"Loading...","noresult":"No Result","tutorial":"Tutorial","search":"Search","bootcamp":"Bootcamp"}}}}}]}},"pageContext":{"locale":"en","old":"termsmd","headings":[{"value":"Glossary","depth":1}],"fileAbsolutePath":"/home/markus/Documents/git/haystack-io/src/pages/docs/site/en/usage/usage/terms.md","editPath":"usage/usage/terms.rst","allMenus":[{"lang":"en","menuList":[{"id":"usage_haystack","title":"Usage","label1":"","label2":"","label3":"","order":0,"isMenu":true},{"id":"intromd","title":"What is Haystack","label1":"usage_haystack","label2":"","label3":"","order":0,"isMenu":null},{"id":"get_startedmd","title":"Get Started","label1":"usage_haystack","label2":"","label3":"","order":1,"isMenu":null},{"id":"databasemd","title":"Document Store","label1":"usage_haystack","label2":"","label3":"","order":2,"isMenu":null},{"id":"retrievermd","title":"Retriever","label1":"usage_haystack","label2":"","label3":"","order":3,"isMenu":null},{"id":"readermd","title":"Reader","label1":"usage_haystack","label2":"","label3":"","order":4,"isMenu":null},{"id":"domain_adaptionmd","title":"Domain Adaption","label1":"usage_haystack","label2":"","label3":"","order":5,"isMenu":null},{"id":"termsmd","title":"Glossary","label1":"usage_haystack","label2":"","label3":"","order":6,"isMenu":null},{"id":"tutorials_haystack","title":"Tutorials","label1":"","label2":"","label3":"","order":1,"isMenu":true},{"id":"tutorial1md","title":"Task: Question Answering for Game of Thrones","label1":"tutorials_haystack","label2":"","label3":"","order":0,"isMenu":null},{"id":"tutorial2md","title":"Fine-tuning a model on your own data","label1":"tutorials_haystack","label2":"","label3":"","order":1,"isMenu":null},{"id":"tutorial3md","title":"Task: Build a Question Answering pipeline without Elasticsearch","label1":"tutorials_haystack","label2":"","label3":"","order":2,"isMenu":null},{"id":"tutorial4md","title":"FAQ-Style QA: Utilizing existing FAQs for Question Answering","label1":"tutorials_haystack","label2":"","label3":"","order":3,"isMenu":null},{"id":"tutorial5md","title":"Evaluation","label1":"tutorials_haystack","label2":"","label3":"","order":4,"isMenu":null},{"id":"tutorial6md","title":"Better retrieval via Dense Passage Retrieval","label1":"tutorials_haystack","label2":"","label3":"","order":5,"isMenu":null},{"id":"api_haystack","title":"API","label1":"","label2":"","label3":"","order":2,"isMenu":true},{"id":"apidatabasemd","title":"Database","label1":"api_haystack","label2":"","label3":"","order":0,"isMenu":null},{"id":"apiretrievermd","title":"Retriever","label1":"api_haystack","label2":"","label3":"","order":1,"isMenu":null},{"id":"apireadermd","title":"Reader","label1":"api_haystack","label2":"api_haystack","label3":"","order":2,"isMenu":null},{"id":"apiindexingmd","title":"Indexing","label1":"api_haystack","label2":"","label3":"","order":3,"isMenu":null},{"id":"rest_apimd","title":"Rest API","label1":"api_haystack","label2":"","label3":"","order":4,"isMenu":null},{"id":"file_convertersmd","title":"File Converters","label1":"api_haystack","label2":"","label3":"","order":5,"isMenu":null}],"absolutePath":"/home/markus/Documents/git/haystack-io/src/pages/docs/site/en/menuStructure/menu.json"}],"newHtml":"<h1>Glossary</h1>\n<p><strong>BERT</strong> - A popular, transformer based language model which has been improved upon but is still considered a common benchmark.</p>\n<p><strong>Dense</strong> - Vectors that contain many non-zero values are considered dense.\nRetrieval methods can also be called dense if they create dense vector representations of documents.</p>\n<p><strong>Document</strong> - A Document in Haystack refers to the individual pieces of text that are stored in the DocumentStore.\nMultiple Documents might originally come from the one file.\nIt is ultimately up to you how to divide up your corpus into Documents.</p>\n<p><strong>Document Store</strong> - The component in Haystack that stores the text documents and their metadata.\nCan have a variety of backends such as Elasticsearch, SQL or FAISS.</p>\n<p><strong>FARM</strong> - An open-source transfer learning <a href=\"https://github.com/deepset-ai/FARM\">framework</a> by deepset.\nFARM’s question answering models are used in Haystack’s Readers.</p>\n<p><strong>Finder</strong> - The component in Haystack that connects the Retriever to the Reader.</p>\n<p><strong>Indexing</strong> - To store data in a database in a way that optimises retrieval time.\nThe exact steps involved in indexing depend on what kind of retrieval method is chosen.</p>\n<p><strong>Language Model</strong> - The component in an NLP model that stores general language understanding, but no task specific knowledge.</p>\n<p><strong>Model Hub</strong> - The <a href=\"https://huggingface.co/models\">repository</a> set up by HuggingFace where trained models can be saved to and loaded from.\nWith Haystack, you can directly load and use any question answering model found on the model hub.</p>\n<p><strong>Neural Network</strong> - A machine learning architecture composed of artificial neurons that learn a task when exposed to labelled training data.</p>\n<p><strong>Prediction Head</strong> - The modelling component that adapts the general knowledge of the language model for a specific task.\nIn question answering models (and hence in Haystack Readers), this is usually a single layer neural network.</p>\n<p><strong>Querying</strong> - The task of returning relevant documents from a database.</p>\n<p><strong>Question Answering (QA)</strong> - A popular task in the world of NLP where systems have to find answers to questions.\nThe term is generally used to refer to extractive question answering,\nwhere a system has to find the minimal text span in a given document that contains the answer to the question.</p>\n<p><strong>Reader</strong> - The component in Haystack that does the closest reading of a document to extract\nthe exact text which answers a question.\nIt is, at its core, a trained Question Answering model.</p>\n<p><strong>Retriever</strong> - A lightweight filter that selects only the most relevant documents for the Reader to further process.</p>\n<p><strong>Semantic Search</strong> - A style of search that relies not on the matching of exact string forms\nbut on the similarity of meaning between a query and a piece of text.</p>\n<p><strong>Sparse</strong> - Vectors that are composed primarily of zeros are called sparse.\nRetrieval methods are also considered sparse if they build sparse vector representations of documents.</p>\n<p><strong>SQuAD</strong> - The <a href=\"https://rajpurkar.github.io/SQuAD-explorer/\">Stanford Question Answering Dataset</a> is the defacto standard QA dataset.\nThe documents are paragraphs from Wikipedia and the question / answer pairs are created by human annotators.</p>\n<p><strong>Transformers</strong> - Originally refers to the deep learning architecture that is composed of stacked self-attention layers\n(first conceptualised <a href=\"https://arxiv.org/pdf/1706.03762.pdf\">here</a>).\nCan also refer to HuggingFace’s <a href=\"https://github.com/huggingface/transformers\">repository</a>\nwhich contains implementations of popular model architectures.</p>"}},"staticQueryHashes":[]}