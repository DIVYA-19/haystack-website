{"componentChunkName":"component---src-templates-doc-template-js","path":"/en/docs/template4md","result":{"data":{"markdownRemark":{"frontmatter":{"id":"template4md","title":"Tutorial 4"}},"allFile":{"edges":[{"node":{"relativeDirectory":"layout","childLayoutJson":{"layout":{"header":{"quick":"Quick Start","benchmarks":"Benchmarks","why":"Why Milvus","gui":"Admin","tutorials":"Tutorials","solution":"Scenarios","about":"About Milvus","doc":"Docs","blog":"Blog","try":"Try","loading":"Loading...","noresult":"No Result","tutorial":"Tutorial","search":"Search","bootcamp":"Bootcamp"}}}}}]}},"pageContext":{"locale":"en","old":"template4md","headings":[{"value":"“FAQ-Style QA”: Utilizing existing FAQs for Question Answering","depth":1},{"value":"Start an Elasticsearch server","depth":2},{"value":"Init the DocumentStore","depth":2},{"value":"Create a Retriever using embeddings","depth":2},{"value":"Prepare & Index FAQ data","depth":2},{"value":"Ask questions","depth":2}],"fileAbsolutePath":"/home/markus/Documents/git/haystack-io/src/pages/docs/site/en/tutorials/tutorials/4.md","editPath":"tutorials/tutorials/4.md","allMenus":[{"lang":"en","menuList":[{"id":"usage_haystack","title":"Usage","label1":"","label2":"","label3":"","order":0,"isMenu":true},{"id":"intromd","title":"What is Haystack","label1":"usage_haystack","label2":"","label3":"","order":0,"isMenu":null},{"id":"get_startedmd","title":"Get Started","label1":"usage_haystack","label2":"","label3":"","order":1,"isMenu":null},{"id":"databasemd","title":"Document Store","label1":"usage_haystack","label2":"","label3":"","order":2,"isMenu":null},{"id":"retrievermd","title":"Retriever","label1":"usage_haystack","label2":"","label3":"","order":3,"isMenu":null},{"id":"readermd","title":"Reader","label1":"usage_haystack","label2":"","label3":"","order":4,"isMenu":null},{"id":"domain_adaptionmd","title":"Domain Adaption","label1":"usage_haystack","label2":"","label3":"","order":5,"isMenu":null},{"id":"termsmd","title":"Glossary","label1":"usage_haystack","label2":"","label3":"","order":6,"isMenu":null},{"id":"tutorials_haystack","title":"Tutorials","label1":"","label2":"","label3":"","order":1,"isMenu":true},{"id":"tutorial1md","title":"Task: Question Answering for Game of Thrones","label1":"tutorials_haystack","label2":"","label3":"","order":0,"isMenu":null},{"id":"tutorial2md","title":"Fine-tuning a model on your own data","label1":"tutorials_haystack","label2":"","label3":"","order":1,"isMenu":null},{"id":"tutorial3md","title":"Task: Build a Question Answering pipeline without Elasticsearch","label1":"tutorials_haystack","label2":"","label3":"","order":2,"isMenu":null},{"id":"tutorial4md","title":"FAQ-Style QA: Utilizing existing FAQs for Question Answering","label1":"tutorials_haystack","label2":"","label3":"","order":3,"isMenu":null},{"id":"tutorial5md","title":"Evaluation","label1":"tutorials_haystack","label2":"","label3":"","order":4,"isMenu":null},{"id":"tutorial6md","title":"Better retrieval via Dense Passage Retrieval","label1":"tutorials_haystack","label2":"","label3":"","order":5,"isMenu":null},{"id":"api_haystack","title":"API","label1":"","label2":"","label3":"","order":2,"isMenu":true},{"id":"apidatabasemd","title":"Database","label1":"api_haystack","label2":"","label3":"","order":0,"isMenu":null},{"id":"apiretrievermd","title":"Retriever","label1":"api_haystack","label2":"","label3":"","order":1,"isMenu":null},{"id":"apireadermd","title":"Reader","label1":"api_haystack","label2":"api_haystack","label3":"","order":2,"isMenu":null},{"id":"apiindexingmd","title":"Indexing","label1":"api_haystack","label2":"","label3":"","order":3,"isMenu":null},{"id":"rest_apimd","title":"Rest API","label1":"api_haystack","label2":"","label3":"","order":4,"isMenu":null},{"id":"file_convertersmd","title":"File Converters","label1":"api_haystack","label2":"","label3":"","order":5,"isMenu":null}],"absolutePath":"/home/markus/Documents/git/haystack-io/src/pages/docs/site/en/menuStructure/menu.json"}],"newHtml":"<h1>“FAQ-Style QA”: Utilizing existing FAQs for Question Answering</h1>\n<p>While <em>extractive Question Answering</em> works on pure texts and is\ntherefore more generalizable, there’s also a common alternative that\nutilizes existing FAQ data.</p>\n<p><strong>Pros</strong>:</p>\n<ul>\n<li>Very fast at inference time</li>\n<li>Utilize existing FAQ data</li>\n<li>Quite good control over answers</li>\n</ul>\n<p><strong>Cons</strong>:</p>\n<ul>\n<li>Generalizability: We can only answer questions that are similar to\nexisting ones in FAQ</li>\n</ul>\n<p>In some use cases, a combination of extractive QA and FAQ-style can also\nbe an interesting option.</p>\n<p><em>Use this</em>\n<a href=\"https://colab.research.google.com/github/deepset-ai/haystack/blob/master/tutorials/Tutorial4_Tutorial4_FAQ_style_QA.ipynb\">link</a>\n<em>to open the notebook in Google Colab.</em></p>\n<pre><code># Install the latest release of Haystack in your own environment\n#! pip install farm-haystack\n\n# Install the latest master of Haystack and install the version of torch that works with the colab GPUs\n!pip install git+https://github.com/deepset-ai/haystack.git\n!pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n</code></pre>\n<pre><code>from haystack import Finder\nfrom haystack.database.elasticsearch import ElasticsearchDocumentStore\n\nfrom haystack.retriever.dense import EmbeddingRetriever\nfrom haystack.utils import print_answers\nimport pandas as pd\nimport requests\n</code></pre>\n<h2>Start an Elasticsearch server</h2>\n<p>You can start Elasticsearch on your local machine instance using Docker.\nIf Docker is not readily available in your environment (eg., in Colab\nnotebooks), then you can manually download and execute Elasticsearch\nfrom source.</p>\n<pre><code># Recommended: Start Elasticsearch using Docker\n# ! docker run -d -p 9200:9200 -e \"discovery.type=single-node\" elasticsearch:7.6.2\n</code></pre>\n<pre><code># In Colab / No Docker environments: Start Elasticsearch from source\n! wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.6.2-linux-x86_64.tar.gz -q\n! tar -xzf elasticsearch-7.6.2-linux-x86_64.tar.gz\n! chown -R daemon:daemon elasticsearch-7.6.2\n\nimport os\nfrom subprocess import Popen, PIPE, STDOUT\nes_server = Popen(['elasticsearch-7.6.2/bin/elasticsearch'],\n                   stdout=PIPE, stderr=STDOUT,\n                   preexec_fn=lambda: os.setuid(1)  # as daemon\n                  )\n# wait until ES has started\n! sleep 30\n</code></pre>\n<h2>Init the DocumentStore</h2>\n<p>In contrast to Tutorial 1 (extractive QA), we:</p>\n<ul>\n<li>specify the name of our <code>text_field</code> in Elasticsearch that we want\nto return as an answer</li>\n<li>specify the name of our <code>embedding_field</code> in Elasticsearch where\nwe’ll store the embedding of our question and that is used later for\ncalculating our similarity to the incoming user question</li>\n<li>set <code>excluded_meta_data=[\"question_emb\"]</code> so that we don’t return\nthe huge embedding vectors in our search results</li>\n</ul>\n<pre><code>from haystack.database.elasticsearch import ElasticsearchDocumentStore\ndocument_store = ElasticsearchDocumentStore(host=\"localhost\", username=\"\", password=\"\",\n                                            index=\"document\",\n                                            embedding_field=\"question_emb\",\n                                            embedding_dim=768,\n                                            excluded_meta_data=[\"question_emb\"])\n</code></pre>\n<h2>Create a Retriever using embeddings</h2>\n<p>Instead of retrieving via Elasticsearch’s plain BM25, we want to use\nvector similarity of the questions (user question vs. FAQ ones). We can\nuse the <code>EmbeddingRetriever</code> for this purpose and specify a model that\nwe use for the embeddings.</p>\n<pre><code>retriever = EmbeddingRetriever(document_store=document_store, embedding_model=\"deepset/sentence_bert\", use_gpu=False)\n</code></pre>\n<h2>Prepare &#x26; Index FAQ data</h2>\n<p>We create a pandas dataframe containing some FAQ data (i.e curated pairs\nof question + answer) and index those in elasticsearch. Here: We\ndownload some question-answer pairs related to COVID-19</p>\n<pre><code># Download\ntemp = requests.get(\"https://raw.githubusercontent.com/deepset-ai/COVID-QA/master/data/faqs/faq_covidbert.csv\")\nopen('small_faq_covid.csv', 'wb').write(temp.content)\n\n# Get dataframe with columns \"question\", \"answer\" and some custom metadata\ndf = pd.read_csv(\"small_faq_covid.csv\")\n# Minimal cleaning\ndf.fillna(value=\"\", inplace=True)\ndf[\"question\"] = df[\"question\"].apply(lambda x: x.strip())\nprint(df.head())\n\n# Get embeddings for our questions from the FAQs\nquestions = list(df[\"question\"].values)\ndf[\"question_emb\"] = retriever.embed_queries(texts=questions)\ndf[\"question_emb\"] = df[\"question_emb\"].apply(list) # convert from numpy to list for ES indexing\ndf = df.rename(columns={\"answer\": \"text\"})\n\n# Convert Dataframe to list of dicts and index them in our DocumentStore\ndocs_to_index = df.to_dict(orient=\"records\")\ndocument_store.write_documents(docs_to_index)\n</code></pre>\n<h2>Ask questions</h2>\n<p>Initialize a Finder (this time without a reader) and ask questions</p>\n<pre><code>finder = Finder(reader=None, retriever=retriever)\nprediction = finder.get_answers_via_similar_questions(question=\"How is the virus spreading?\", top_k_retriever=10)\nprint_answers(prediction, details=\"all\")\n</code></pre>"}},"staticQueryHashes":[]}