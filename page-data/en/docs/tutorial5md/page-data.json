{"componentChunkName":"component---src-templates-doc-template-js","path":"/en/docs/tutorial5md","result":{"data":{"markdownRemark":{"frontmatter":{"id":"tutorial5md","title":"Tutorial 5"}},"allFile":{"edges":[{"node":{"relativeDirectory":"layout","childLayoutJson":{"layout":{"header":{"quick":"Quick Start","benchmarks":"Benchmarks","why":"Why Haystack","gui":"Admin","tutorials":"Tutorials","solution":"Scenarios","about":"About Haystack","doc":"Docs","blog":"Blog","try":"Try","loading":"Loading...","noresult":"No Result","tutorial":"Tutorial","search":"Search","bootcamp":"Bootcamp"}}}}}]}},"pageContext":{"locale":"en","old":"tutorial5md","headings":[{"value":"Evaluation","depth":1},{"value":"Start an Elasticsearch server","depth":2},{"value":"Initialize components of QA-System","depth":2},{"value":"Evaluation of Retriever","depth":2},{"value":"Evaluation of Reader","depth":2},{"value":"Evaluation of Finder","depth":2}],"fileAbsolutePath":"/home/markus/Documents/git/haystack-io/src/pages/docs/site/en/tutorials/tutorials/5.md","editPath":"tutorials/tutorials/5.rst","allMenus":[{"lang":"en","menuList":[{"id":"usage_haystack","title":"Usage","label1":"","label2":"","label3":"","order":0,"isMenu":true},{"id":"intromd","title":"What is Haystack","label1":"usage_haystack","label2":"","label3":"","order":0,"isMenu":null},{"id":"get_startedmd","title":"Get Started","label1":"usage_haystack","label2":"","label3":"","order":1,"isMenu":null},{"id":"databasemd","title":"Document Store","label1":"usage_haystack","label2":"","label3":"","order":2,"isMenu":null},{"id":"retrievermd","title":"Retriever","label1":"usage_haystack","label2":"","label3":"","order":3,"isMenu":null},{"id":"readermd","title":"Reader","label1":"usage_haystack","label2":"","label3":"","order":4,"isMenu":null},{"id":"domain_adaptionmd","title":"Domain Adaption","label1":"usage_haystack","label2":"","label3":"","order":5,"isMenu":null},{"id":"termsmd","title":"Glossary","label1":"usage_haystack","label2":"","label3":"","order":6,"isMenu":null},{"id":"tutorials_haystack","title":"Tutorials","label1":"","label2":"","label3":"","order":1,"isMenu":true},{"id":"tutorial1md","title":"Task: Question Answering for Game of Thrones","label1":"tutorials_haystack","label2":"","label3":"","order":0,"isMenu":null},{"id":"tutorial2md","title":"Fine-tuning a model on your own data","label1":"tutorials_haystack","label2":"","label3":"","order":1,"isMenu":null},{"id":"tutorial3md","title":"Task: Build a Question Answering pipeline without Elasticsearch","label1":"tutorials_haystack","label2":"","label3":"","order":2,"isMenu":null},{"id":"tutorial4md","title":"FAQ-Style QA: Utilizing existing FAQs for Question Answering","label1":"tutorials_haystack","label2":"","label3":"","order":3,"isMenu":null},{"id":"tutorial5md","title":"Evaluation","label1":"tutorials_haystack","label2":"","label3":"","order":4,"isMenu":null},{"id":"tutorial6md","title":"Better retrieval via Dense Passage Retrieval","label1":"tutorials_haystack","label2":"","label3":"","order":5,"isMenu":null},{"id":"api_haystack","title":"API","label1":"","label2":"","label3":"","order":2,"isMenu":true},{"id":"apidatabasemd","title":"Database","label1":"api_haystack","label2":"","label3":"","order":0,"isMenu":null},{"id":"apiretrievermd","title":"Retriever","label1":"api_haystack","label2":"","label3":"","order":1,"isMenu":null},{"id":"apireadermd","title":"Reader","label1":"api_haystack","label2":"api_haystack","label3":"","order":2,"isMenu":null},{"id":"apiindexingmd","title":"Indexing","label1":"api_haystack","label2":"","label3":"","order":3,"isMenu":null},{"id":"rest_apimd","title":"Rest API","label1":"api_haystack","label2":"","label3":"","order":4,"isMenu":null},{"id":"file_convertersmd","title":"File Converters","label1":"api_haystack","label2":"","label3":"","order":5,"isMenu":null}],"absolutePath":"/home/markus/Documents/git/haystack-io/src/pages/docs/site/en/menuStructure/menu.json"}],"newHtml":"<h1>Evaluation</h1>\n<p>To be able to make a statement about the performance of a\nquestion-answering system, it is important to evalute it. Furthermore,\nevaluation allows to determine which parts of the system can be\nimproved.</p>\n<h2>Start an Elasticsearch server</h2>\n<p>You can start Elasticsearch on your local machine instance using Docker.\nIf Docker is not readily available in your environment (eg., in Colab\nnotebooks), then you can manually download and execute Elasticsearch\nfrom source.</p>\n<pre><code># Install the latest release of Haystack in your own environment\n#! pip install farm-haystack\n\n# Install the latest master of Haystack and install the version of torch that works with the colab GPUs\n!pip install git+https://github.com/deepset-ai/haystack.git\n!pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n</code></pre>\n<pre><code># In Colab / No Docker environments: Start Elasticsearch from source\n! wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.6.2-linux-x86_64.tar.gz -q\n! tar -xzf elasticsearch-7.6.2-linux-x86_64.tar.gz\n! chown -R daemon:daemon elasticsearch-7.6.2\n\nimport os\nfrom subprocess import Popen, PIPE, STDOUT\nes_server = Popen(['elasticsearch-7.6.2/bin/elasticsearch'],\n                   stdout=PIPE, stderr=STDOUT,\n                   preexec_fn=lambda: os.setuid(1)  # as daemon\n                  )\n# wait until ES has started\n! sleep 30\n</code></pre>\n<pre><code>from farm.utils import initialize_device_settings\n\ndevice, n_gpu = initialize_device_settings(use_cuda=True)\n</code></pre>\n<pre><code>from haystack.indexing.utils import fetch_archive_from_http\n\n# Download evaluation data, which is a subset of Natural Questions development set containing 50 documents\ndoc_dir = \"../data/nq\"\ns3_url = \"https://s3.eu-central-1.amazonaws.com/deepset.ai-farm-qa/datasets/nq_dev_subset_v2.json.zip\"\nfetch_archive_from_http(url=s3_url, output_dir=doc_dir)\n</code></pre>\n<pre><code># make sure these indices do not collide with existing ones, the indices will be wiped clean before data is inserted\ndoc_index = \"tutorial5_docs\"\nlabel_index = \"tutorial5_labels\"\n</code></pre>\n<pre><code># Connect to Elasticsearch\nfrom haystack.database.elasticsearch import ElasticsearchDocumentStore\n\n# Connect to Elasticsearch\ndocument_store = ElasticsearchDocumentStore(host=\"localhost\", username=\"\", password=\"\", index=\"document\",\n                                            create_index=False, embedding_field=\"emb\",\n                                            embedding_dim=768, excluded_meta_data=[\"emb\"])\n</code></pre>\n<pre><code># Add evaluation data to Elasticsearch database\n# We first delete the custom tutorial indices to not have duplicate elements\ndocument_store.delete_all_documents(index=doc_index)\ndocument_store.delete_all_documents(index=label_index)\ndocument_store.add_eval_data(filename=\"../data/nq/nq_dev_subset_v2.json\", doc_index=doc_index, label_index=label_index)\n</code></pre>\n<h2>Initialize components of QA-System</h2>\n<pre><code># Initialize Retriever\nfrom haystack.retriever.sparse import ElasticsearchRetriever\nretriever = ElasticsearchRetriever(document_store=document_store)\n# Alternative: Evaluate DensePassageRetriever\n# Note, that DPR works best when you index short passages &#x3C; 512 tokens as only those tokens will be used for the embedding.\n# Here, for nq_dev_subset_v2.json we have avg. num of tokens = 5220(!).\n# DPR still outperforms Elastic's BM25 by a small margin here.\n# from haystack.retriever.dense import DensePassageRetriever\n# retriever = DensePassageRetriever(document_store=document_store,\n#                                  query_embedding_model=\"facebook/dpr-question_encoder-single-nq-base\",\n#                                  passage_embedding_model=\"facebook/dpr-ctx_encoder-single-nq-base\",\n#                                  use_gpu=True,\n#                                  embed_title=True,\n#                                  max_seq_len=256,\n#                                  batch_size=16,\n#                                  remove_sep_tok_from_untitled_passages=True)\n#document_store.update_embeddings(retriever, index=doc_index)\n</code></pre>\n<pre><code># Initialize Reader\nfrom haystack.reader.farm import FARMReader\n\nreader = FARMReader(\"deepset/roberta-base-squad2\", top_k_per_candidate=4)\n</code></pre>\n<pre><code># Initialize Finder which sticks together Reader and Retriever\nfrom haystack.finder import Finder\n\nfinder = Finder(reader, retriever)\n</code></pre>\n<h2>Evaluation of Retriever</h2>\n<pre><code>## Evaluate Retriever on its own\nretriever_eval_results = retriever.eval(top_k=20, label_index=label_index, doc_index=doc_index)\n## Retriever Recall is the proportion of questions for which the correct document containing the answer is\n## among the correct documents\nprint(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n## Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\nprint(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n</code></pre>\n<h2>Evaluation of Reader</h2>\n<pre><code># Evaluate Reader on its own\nreader_eval_results = reader.eval(document_store=document_store, device=device, label_index=label_index, doc_index=doc_index)\n# Evaluation of Reader can also be done directly on a SQuAD-formatted file without passing the data to Elasticsearch\n#reader_eval_results = reader.eval_on_file(\"../data/nq\", \"nq_dev_subset_v2.json\", device=device)\n\n## Reader Top-N-Accuracy is the proportion of predicted answers that match with their corresponding correct answer\nprint(\"Reader Top-N-Accuracy:\", reader_eval_results[\"top_n_accuracy\"])\n## Reader Exact Match is the proportion of questions where the predicted answer is exactly the same as the correct answer\nprint(\"Reader Exact Match:\", reader_eval_results[\"EM\"])\n## Reader F1-Score is the average overlap between the predicted answers and the correct answers\nprint(\"Reader F1-Score:\", reader_eval_results[\"f1\"])\n</code></pre>\n<h2>Evaluation of Finder</h2>\n<pre><code># Evaluate combination of Reader and Retriever through Finder\n# Evaluate combination of Reader and Retriever through Finder\nfinder_eval_results = finder.eval(top_k_retriever=1, top_k_reader=10, label_index=label_index, doc_index=doc_index)\nfinder.print_eval_results(finder_eval_results)\n</code></pre>"}},"staticQueryHashes":[]}